# 小文件合并存储

小文件合并存储是目前优化LOSF问题最为成功的策略，已经被包括Facebook Haystack和淘宝TFS在内多个分布式存储系统采用。
它通过多个逻辑文件共享同一个物理文件，将多个小文件合并存储到一个大文件中，实现高效的小文件存储。为什么这种策略对LOSF效果显著呢？

首先，减少了大量元数据。通过将大量的小文件存储到一个大文件中，从而把大量的小文件数据变成大文件数据，减少了文件数量，
从而减少了元数据服务中的元数据数量，提高了元数据的检索和查询效率，降低了文件读写的I /O操作延时，节省了大量的数据传输时间。
LOSF元数据开销所占比重大，大幅减少元数据，将直接导致性能的显著提升。合并后的大文件存储在磁盘文件系统之上，
同时也大大降低了磁盘文件系统在元数据和I/O方面的压力，这点可以改善每个节点的存储性能。小文件的元数据和数据会一并存储在大文件中，
并形成索引文件，访问时通过索引进行定位。索引文件采用预加载到Cache的策略，可以实现随机读写小文件只需要一次I/O。

其次，增加了数据局部性，提高了存储效率。磁盘文件系统或者分布式文件系统中，文件的元数据和数据存储在不同位置。
采用合并存储机制后，小文件的元数据和数据可以一并连续存储大文件中，这大大增强了单个小文件内部的数据局部性。
小文件合并过程中，可以利用文件之间的空间局部性、时间局部性以及关联，尽量将可能连续访问的小文件在大文件中进行
连续存储，增强了小文件之间的数据局部性。这直接降低了磁盘上随机I/O比率，转换成了顺序I/O，能够有效提高I/O读写性能。
另外，小文件单独存储会形成外部和内部碎片，而合并存储后存储碎片将大大降低，这极大提高了LOSF存储效率。

再次，简化了I/O访问流程。采用小文件合并存储后，I/O访问流程发生了极大变化，主要体现在存储节点磁盘文件系统上。
根据之前的阐述，磁盘文件系统读写一个小文件，最大的系统消耗在open系统调用，需要进行路径查找do_path_lookup，
将路径名进行分量解析，转换成对应文件在内核中内部表示。这个过程非常占用系统开销，尤其是深目录下的文件。
而经过合并，很多小文件共享一个大文件，open操作转换成了开销小很多的seek操作，根据索引定位到大文件内部相应位置即可，
也不需要在内核中创建相关VFS数据对象，这节省了原先绝大部分的系统开销。

大文件加上索引文件，小文件合并存储实际上相当于一个微型文件系统。这种机制对于WORM(Write Once Read Many)
模式的分布式存储系统非常适合，而不适合允许改写和删除的存储系统。因为文件改写和删除操作，会造成大文件内部的碎片空洞，
如果进行空间管理并在合适时候执行碎片整理，实现比较复杂而且产生额外开销。如果不对碎片进行处理，采用追加写的方式，
一方面会浪费存储容量，另一方面又会破坏数据局部性，增加数据分布的随机性，导致读性能下降。此外，如果支持随机读写，
大小文件如何统一处理，小文件增长成大文件，大文件退化为小文件，这些问题都是在实际处理时面临的挑战。